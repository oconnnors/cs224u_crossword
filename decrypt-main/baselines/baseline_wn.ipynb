{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Heuristic wordnet baseline\"\"\"\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k_json_folder = '../puzzles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from decrypt.scrape_parse import (\n",
    "    load_guardian_splits,\n",
    "    load_guardian_splits_disjoint_hash\n",
    ")\n",
    "\n",
    "import random\n",
    "from typing import *\n",
    "\n",
    "import jellyfish\n",
    "\n",
    "from multiset import Multiset\n",
    "from nltk.corpus import wordnet as wn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from decrypt.common.puzzle_clue import GuardianClue\n",
    "from decrypt.common.util_wordnet import all_inflect\n",
    "from decrypt.common import validation_tools as vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wordnet functions to produce reverse dictionary sets\n",
    "\n",
    "def normalize(lemma):\n",
    "    \"\"\"Wordnet returns words with underscores and hyphens. We replace them with spaces. This possibly does not work well with lemminflect.\"\"\"\n",
    "    return lemma.replace(\"_\",\" \").replace(\"-\",\" \")\n",
    "\n",
    "def get_syns(w: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Get all synonyms of w\n",
    "    \"\"\"\n",
    "    ret = set()\n",
    "    for ss in wn.synsets(w):\n",
    "        for l in ss.lemma_names():\n",
    "            ret.add(normalize(l))\n",
    "    return ret\n",
    "\n",
    "def get_syns_hypo1(w: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Get all synonyms and hyponyms to depth 1\n",
    "    \"\"\"\n",
    "    ret = set()\n",
    "    for ss in wn.synsets(w):\n",
    "        for l in ss.lemma_names():\n",
    "            ret.add(normalize(l))\n",
    "        for rel_ss in ss.hyponyms():\n",
    "            for l in rel_ss.lemma_names():\n",
    "                ret.add(normalize(l))\n",
    "    return ret\n",
    "\n",
    "def get_syns_hypo_all(w: str, include_hyper=False, depth=3) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Get all synonyms; hyponyms to depth, depth; and hypernyms to depth, depth,\n",
    "    if include_hyper is True\n",
    "\n",
    "    :param w: word to lookup\n",
    "    :param include_hyper: whether to do hypernym lookup\n",
    "    :param depth: how far to go in hyponym / hypernym traversal\n",
    "    \"\"\"\n",
    "    ret = set()\n",
    "    for ss in wn.synsets(w):\n",
    "        for l in ss.lemma_names():\n",
    "            ret.add(normalize(l))\n",
    "        if include_hyper:\n",
    "            for rel_ss in ss.closure(lambda s: s.hypernyms(), depth=depth):\n",
    "                for l in rel_ss.lemma_names():\n",
    "                    ret.add(normalize(l))\n",
    "        for rel_ss in ss.closure(lambda s: s.hyponyms(), depth=depth):\n",
    "            for l in rel_ss.lemma_names():\n",
    "                ret.add(normalize(l))\n",
    "    return ret\n",
    "\n",
    "def get_first_and_last_word(c: GuardianClue):\n",
    "    clue_words = c.clue.split(\" \")\n",
    "    return clue_words[0], clue_words[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pct_sim(str1, str2):\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    lev = jellyfish.levenshtein_distance(str1, str2)\n",
    "    return 1.0 - lev/max_len\n",
    "\n",
    "def eval_wn(val_set: List[GuardianClue],\n",
    "            fcn: Callable,\n",
    "            do_fuzzy: bool,\n",
    "            do_rank: bool = False,\n",
    "            **fcn_kwargs):\n",
    "    \"\"\"\n",
    "    :param val_set:\n",
    "    :param fcn:\n",
    "    :param do_fuzzy:\n",
    "    :param fcn_kwargs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rng = random.Random()\n",
    "    rng.seed(42)\n",
    "\n",
    "    model_outputs = []\n",
    "    for val_gc in tqdm(val_set):\n",
    "        all_possible = set()\n",
    "\n",
    "        # add the direct synonyms\n",
    "        for w in get_first_and_last_word(val_gc):\n",
    "            all_possible.update(list(fcn(w.lower(), **fcn_kwargs)))\n",
    "\n",
    "        # potentially add lemmas\n",
    "        if do_fuzzy:\n",
    "            orig = all_possible.copy()\n",
    "            for w in orig:\n",
    "                all_possible.update(all_inflect(w, None))\n",
    "\n",
    "        _, filtered = vt.filter_to_len(val_gc.soln_with_spaces, all_possible)\n",
    "        filtered_final = [x[0] for x in filtered]   # go back to with spaces\n",
    "\n",
    "        # jellyfish score\n",
    "        # # if do_rank:\n",
    "        # #     list_with_rank = []\n",
    "        # #     for out in filtered_final:\n",
    "        # #         score = pct_sim(out, val_gc.clue)\n",
    "        # #         list_with_rank.append((out, score))\n",
    "        # #     # sort\n",
    "        # #     list_sorted = sorted(list_with_rank, key=lambda x: x[1], reverse=True)\n",
    "        # #     # take the word not the score\n",
    "        #     filtered_final = [x[0] for x in list_sorted]\n",
    "\n",
    "        # simple character overlap\n",
    "        if do_rank:\n",
    "            list_with_rank = []\n",
    "            mset = Multiset(val_gc.clue)\n",
    "            for out in filtered_final:\n",
    "                score = len(mset.intersection(Multiset(out)))\n",
    "                list_with_rank.append((out, score))\n",
    "            # sort\n",
    "            list_sorted = sorted(list_with_rank, key=lambda x: x[1], reverse=True)\n",
    "            # take the word not the score\n",
    "            filtered_final = [x[0] for x in list_sorted]\n",
    "        else:\n",
    "            rng.shuffle(filtered_final)\n",
    "\n",
    "        mp = vt.ModelPrediction(\n",
    "            idx=val_gc.idx,\n",
    "            input=val_gc.clue_with_lengths(),\n",
    "            target=val_gc.soln_with_spaces,\n",
    "            greedy=\"\",\n",
    "            sampled=filtered_final)\n",
    "\n",
    "        mp.model_eval = vt.eval(mp)\n",
    "        model_outputs.append(mp)\n",
    "\n",
    "    return model_outputs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Below we provide code to run the two models to produce row 1 of Main Results\n",
    "Table 2 in the paper.\n",
    "\n",
    "Other combinations of (unreported) hyperparameters can be tested by changing\n",
    "- the fcn passed to eval_wn\n",
    "- do_fuzzy\n",
    "- do_rank (or changing how ranking is computed -- uncomment the jellyfish code above)\n",
    "\n",
    "Note that for the Main Results Table 2, the metrics we include in the table correspond to\n",
    "- `agg_top_match`\n",
    "- `agg_top_10_after_filter`\n",
    "\n",
    "More details of these metric calculations can be found in `decrypt.common.validation_tools`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# this is the primary baseline\n",
    "######################\n",
    "\n",
    "# naive set\n",
    "def run_primary_wn_naive():\n",
    "    _, _, (_, val_orig, test_orig) = load_guardian_splits(k_json_folder)\n",
    "    out1 = eval_wn(val_orig, fcn=get_syns_hypo1, do_fuzzy=False, do_rank=True) # 1711\n",
    "    print('val results')\n",
    "    vt.all_aggregate(out1, label='syns,hypo1; no fuzzy, ranked by char overlap')\n",
    "\n",
    "    print('test results')\n",
    "    out2 = eval_wn(test_orig, fcn=get_syns_hypo1, do_fuzzy=False, do_rank=True) # 1711\n",
    "    vt.all_aggregate(out2, label='syns,hypo1; no fuzzy, ranked by char overlap')\n",
    "\n",
    "run_primary_wn_naive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##\n",
    "# run on disjoint set\n",
    "##\n",
    "\n",
    "def run_primary_wn_disj2():\n",
    "    _, _, (_, val_orig, test_orig) = load_guardian_splits_disjoint_hash(k_json_folder)\n",
    "    print('val results')\n",
    "    out1 = eval_wn(val_orig, fcn=get_syns_hypo1, do_fuzzy=False, do_rank=True) # 1711\n",
    "    vt.all_aggregate(out1, label='syns,hypo1; no fuzzy, ranked by char overlap')\n",
    "\n",
    "    print('test results')\n",
    "    out2 = eval_wn(test_orig, fcn=get_syns_hypo1, do_fuzzy=False, do_rank=True) # 1711\n",
    "    vt.all_aggregate(out2, label='syns,hypo1; no fuzzy, ranked by char overlap')\n",
    "\n",
    "run_primary_wn_disj2()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
