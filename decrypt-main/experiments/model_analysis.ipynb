{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis section of paper\n",
    "\n",
    "## 6.1 Meta-linguistic properties\n",
    "Table 3b is produced from the statistics that will be outputted in baselines/baseline_t5 and\n",
    "baselines/baseline_knn.\n",
    "\n",
    "Nothing else is required\n",
    "\n",
    "## 6.2 Disjointness\n",
    "This section contains two parts:\n",
    "1. Subset analysis\n",
    "2. Analysis on distinct splits\n",
    "\n",
    "Producing the table rows:\n",
    "1. Row 1 in the Table 3b (naive, entire split) is the same as T5 (lenghts) in the main\n",
    " results table and is produced by running baselines/baseline_t5, i.e.\n",
    "1. Subset not in train - see below for setup\n",
    "1. Naive disjoint - run in the same way as baselines/baseline_t5, but on the naive_disjoint split, i.e.\n",
    "    - Train on the naive disjoint split:\n",
    "```python\n",
    "python train_clues.py --default_train=base --name=baseline_naive_disjoint --project=baseline --wandb_dir='./wandb' --data_dir='../data/clue_json/guardian/naive_disjoint'\n",
    "```\n",
    "    - Eval to get 100 generations (on the best epoch checkpoint), with and without `--test` flag\n",
    "```python\n",
    "python train_clues.py --default_val=base --name=baseline_naive_disjoint_val --project=baseline --data_dir='../data/clue_json/guardian/naive_disjoint' --ckpt_path='./wandb/run_name/files/epoch_10.pth.tar\n",
    "```\n",
    "    - run the eval script\n",
    "`vt.load_and_run_t5('decrypt/t5_outputs/baseline_naive_disjoint_val.preds')`\n",
    "1. word initial disjoint split - same as T5 (lengths) row in main results table (see baselines/baselines_t5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# eval on the subset not seen in train\n",
    "import random\n",
    "from decrypt import config\n",
    "from decrypt.scrape_parse import load_guardian_splits\n",
    "from decrypt.common import validation_tools as vt\n",
    "from decrypt.scrape_parse.util import str_hash as safe_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a function that will filter to those input-output pairs with answers\n",
    "# not seen during training\n",
    "def make_filter_fn():\n",
    "    _, _, (train, _, _) = load_guardian_splits(config.DataDirs.Guardian.json_folder, verify=True)\n",
    "    s = set()\n",
    "    for c in train:\n",
    "        s.add(c.soln_with_spaces)\n",
    "\n",
    "    # return False to omit\n",
    "    def filter_fcn(mp: vt.ModelPrediction):\n",
    "        if mp.target in s:\n",
    "            return False\n",
    "        return True\n",
    "    return filter_fcn\n",
    "\n",
    "\n",
    "vt.load_and_run_t5('outputs/naive_baseline.preds',\n",
    "                   filter_fcn=make_filter_fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the following is not reported in the paper\n",
    "# prepare for set that does not overlap, fuzzily\n",
    "# ie also match on plurals\n",
    "def make_set_inclusion_filter_fcn_fuzz():\n",
    "    _, _, (train, _, _) = load_guardian_splits(config.DataDirs.Guardian.json_folder, verify=True)\n",
    "    s = set()\n",
    "\n",
    "    # fuzzily match plurals\n",
    "    for c in train:\n",
    "        soln = c.soln_with_spaces\n",
    "        if soln.endswith('es'):\n",
    "            s.add(soln[:-2])\n",
    "        if soln.endswith('s'):\n",
    "            s.add(soln[:-1])\n",
    "        s.add(soln + 'es')\n",
    "        s.add(soln + 's')\n",
    "        s.add(soln)\n",
    "\n",
    "    # return False to omit\n",
    "    def filter_fcn(mp: vt.ModelPrediction):\n",
    "        if mp.target in s or mp.target[:-1] in s or mp.target[:-2] in s:\n",
    "            return False\n",
    "        return True\n",
    "    return filter_fcn\n",
    "\n",
    "vt.load_and_run_t5('outputs/naive_baseline.preds',\n",
    "                   filter_fcn=make_set_inclusion_filter_fcn_fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Wordplay minimal task\n",
    "Here we provide code to\n",
    "1. produce the descramble dataset\n",
    "1. run the two variations of the descramble task\n",
    "    - with and without adding the definition\n",
    "    - on random and word-initial disjoint splits\n",
    "    - copy task (i.e. no scrambling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# first prepare the descrambling dataset\n",
    "from decrypt.scrape_parse.acw_load import get_clean_xd_clues\n",
    "from sklearn.model_selection import train_test_split\n",
    "from decrypt.common.util_data import write_json_tuple\n",
    "\n",
    "k_xd_orig_tsv = config.DataDirs.OriginalData.k_xd_cw\n",
    "k_descramble_rand = config.DataDirs.DataExport.descramble_random\n",
    "k_descramble_disj = config.DataDirs.DataExport.descramble_word_init_disjoint\n",
    "\n",
    "# method will produce a version of the ACW dataset that is\n",
    "# - single words that appear in our dictionary\n",
    "# - without exact duplicates (but note that some answers will occur multiple times with different clues\n",
    "# - filtered to answer words with between 4 and 14 characters\n",
    "# - downsampled to 10%\n",
    "def make_descramble_json(seed=42):\n",
    "    stc_map, all_clues = get_clean_xd_clues(k_xd_orig_tsv,\n",
    "                                            remove_if_not_in_dict=True,     # only single words\n",
    "                                            do_filter_dupes=True)\n",
    "\n",
    "    # further filter away anything < 4 chars\n",
    "    all_clues_len = [x for x in all_clues if len(x.soln) > 3 and len(x.soln) < 15]\n",
    "    print(len(all_clues_len))\n",
    "\n",
    "    # downsample to 10 percent\n",
    "    rng = random.Random(42)\n",
    "    all_clues_10per = rng.sample(all_clues_len, k=int(len(all_clues)*.1))\n",
    "    print(len(all_clues_10per))\n",
    "    print(all_clues_10per[0])\n",
    "\n",
    "    # logic the same as scrape_parse.guardian_load.make_disjoint_split()\n",
    "    def make_dataset(disj: bool):\n",
    "        # make json\n",
    "        json_all = []\n",
    "        for c in all_clues_10per:\n",
    "            c.soln = c.soln.lower()\n",
    "            json_dict = dict(defn=c.clue,\n",
    "                             target=c.soln)\n",
    "            json_all.append(json_dict)\n",
    "\n",
    "        train, val = [], []     # list of json dicts\n",
    "        rng.seed(seed)\n",
    "        if disj:\n",
    "            for c in json_all:\n",
    "                idx = safe_hash(c['target'][:2]) % 10\n",
    "                if idx == 0:\n",
    "                    val.append(c)   # val ~ 20k\n",
    "                else:\n",
    "                    train.append(c)\n",
    "            rng.shuffle(train)\n",
    "            rng.shuffle(val)\n",
    "        else:   # not disj\n",
    "            train, val = train_test_split(json_all, test_size=.1, random_state=seed)\n",
    "\n",
    "        return train, val\n",
    "\n",
    "    write_json_tuple(list(make_dataset(disj=False)),    # train, val\n",
    "                     comment=\"\",\n",
    "                     export_dir=k_descramble_rand)\n",
    "\n",
    "    write_json_tuple(list(make_dataset(disj=True)),     # train, val\n",
    "                     comment=\"\",\n",
    "                     export_dir=k_descramble_disj)\n",
    "\n",
    "make_descramble_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run (e.g. on random split with phrasal definition)\n",
    "```python\n",
    "python train_descramble.py --default_train=base --name=descramble_random_phrase --project=descramble --wandb_dir='./wandb' --data_dir='../data/clue_json/descramble/random_split/' --generation_beams=10 --no_save --randomize_train_scramble --add_defn\n",
    "```\n",
    "\n",
    "The other variations we present are\n",
    "- word initial split ('./data/clue_json/descramble/word_initial')\n",
    "- --no_defn (do not append phrase), instead of --add_defn\n",
    "- --copy (to test the identity task)\n",
    "\n",
    "Model analysis (eval) runs are not necessary: we can just read off the metric from the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Wordplay systematic learning\n",
    "- identify clues with anagram of first name\n",
    "- two sets: scramble / substitute\n",
    "- run / evaluate\n",
    "- average character level overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from decrypt.common.label_anagrams import make_label_set\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from typing import *\n",
    "from decrypt.common.substitution import ClueWithSubstitutions, Substitution\n",
    "from decrypt.common.puzzle_clue import BaseClue\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_train_and_val_direct_anag_sets() -> Tuple[List[int], ...]:\n",
    "    # this will load things twice, but whatever\n",
    "    labels = make_label_set()\n",
    "    _, _, (train, val, _) = load_guardian_splits(config.DataDirs.Guardian.json_folder)\n",
    "\n",
    "    # get pre-labeled direct anagram clue sets\n",
    "    def load_set(label_name: str):\n",
    "        idx_to_clues_train = {c.idx: c for c in train}\n",
    "        idx_to_clues_val = {c.idx: c for c in val}\n",
    "        train_set = [idx_to_clues_train[idx] for idx in labels[label_name] if idx in idx_to_clues_train]\n",
    "        val_set = [idx_to_clues_val[idx] for idx in labels[label_name] if idx in idx_to_clues_val]\n",
    "        return train_set, val_set\n",
    "\n",
    "    train_set, val_set = load_set('anag_direct')\n",
    "    print(len(train_set))\n",
    "    print(len(val_set))\n",
    "    return train_set, val_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Filter to clues that work for our substitution\n",
    "# - only one word targets\n",
    "# - no punctuation\n",
    "# Produce clues with 20 substitutions (10 scramble, 10 sub)\n",
    "def get_clues_with_subs(\n",
    "        clue_list: List[BaseClue],\n",
    "        num_subs=10) -> List[ClueWithSubstitutions]:\n",
    "    random.seed(42)\n",
    "\n",
    "    # produce a map from the name length to list of names with that length\n",
    "    def get_names_map() -> Tuple[List[str], Dict[int, List[str]]]:\n",
    "        names = list()\n",
    "        dir_glob = glob(str(config.DataDirs.OriginalData.k_names / \"*.txt\"))\n",
    "        for name_file in dir_glob:\n",
    "            with open(name_file, 'r') as f:\n",
    "                names.extend([x.strip() for x in f.readlines()])\n",
    "\n",
    "        # get mapping from length to names\n",
    "        def make_length_to_names_map():\n",
    "            length_to_names_set = defaultdict(set)\n",
    "            for name in names:\n",
    "                length_to_names_set[len(name)].add(name)\n",
    "\n",
    "            # convert to lists\n",
    "            length_to_names = defaultdict(list)\n",
    "            for k,v in length_to_names_set.items():\n",
    "                length_to_names[k] = list(v)\n",
    "            return length_to_names\n",
    "\n",
    "        all_names = list(set(names))            # dedupe\n",
    "        # len(all_names)\n",
    "        # sum(map(len, names_map.values()))     # total names\n",
    "        names_map = make_length_to_names_map()\n",
    "        return all_names, names_map\n",
    "    all_names_list, names_map = get_names_map()\n",
    "    all_names_set = set(all_names_list)\n",
    "\n",
    "    # For each of the possible clues, look for those that have a first name\n",
    "    clues_with_subs = []        # we accumulate ClueWithSubstitution\n",
    "    for sc in tqdm(clue_list):\n",
    "        if len(sc.lengths) > 1:     # skip multiword outputs\n",
    "            continue\n",
    "\n",
    "        s = sorted(sc.soln.lower())\n",
    "        anagram_substrate = None\n",
    "        word_idx = None\n",
    "\n",
    "        # find the word that was actually the anagram substrate (i.e. we are looking for\n",
    "        # anagrams that are a full word)\n",
    "        words: List[str] = sc.clue_with_lengths().split(' ')\n",
    "        for idx, w in enumerate(words):\n",
    "            if not len(w) == len(s):    # verify length - this cannot be the substrate if it's not correct len\n",
    "                continue\n",
    "            if not w.isalpha():         # skip, e.g. any anagram substrate that has some punctuation\n",
    "                continue\n",
    "            # this one is probably redundant with .isalpha()\n",
    "            if not sorted(w.lower()) == s:  # verify that the word is in fact an anagram\n",
    "                continue\n",
    "            if w in all_names_set:\n",
    "                anagram_substrate = w\n",
    "                word_idx = idx\n",
    "                break\n",
    "        # skip clue if we didn't find the anagram substrate\n",
    "        if anagram_substrate is None:\n",
    "            continue\n",
    "\n",
    "        # success: we found the anagram substrate!\n",
    "        print(sc)\n",
    "\n",
    "        # create substitutions\n",
    "        # we will fill in the substitutions part below with 10 each of\n",
    "        # - scramble\n",
    "        # - new name\n",
    "        sub_clue = ClueWithSubstitutions(\n",
    "            orig_input=sc.clue_with_lengths(),\n",
    "            word_to_be_swapped=anagram_substrate,\n",
    "            target=sc.soln,\n",
    "            substitutions=[]\n",
    "        )\n",
    "\n",
    "        # scramble substition\n",
    "        for i in range(num_subs):\n",
    "            x = list(anagram_substrate.lower())\n",
    "            random.shuffle(x)\n",
    "            new_word = \"\".join(x).capitalize()\n",
    "            words[word_idx] = new_word\n",
    "            new_clue_str = \" \".join(words)\n",
    "            sub_clue.substitutions.append(Substitution(new_clue_str, new_word))\n",
    "\n",
    "        # real name substitutions\n",
    "        subs_list = random.sample(names_map[len(anagram_substrate)], k=num_subs)\n",
    "        for new_word in subs_list:\n",
    "            words[word_idx] = new_word\n",
    "            new_clue_str = \" \".join(words)\n",
    "            sub_clue.substitutions.append(Substitution(new_clue_str, new_word))\n",
    "        clues_with_subs.append(sub_clue)\n",
    "    return clues_with_subs\n",
    "\n",
    "# write json for use by model\n",
    "def write_json(input_list, name):\n",
    "    os.makedirs(config.DataDirs.DataExport.wordplay_dir, exist_ok=True)\n",
    "    fname = config.DataDirs.DataExport.wordplay_dir / f'{name}_subs.json'\n",
    "    with open(fname, 'w') as f:\n",
    "        v_subs_json = [v.to_dict() for v in input_list]\n",
    "        json.dump(v_subs_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_list, val_list = load_train_and_val_direct_anag_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_subs = get_clues_with_subs(val_list)\n",
    "train_subs = get_clues_with_subs(train_list)\n",
    "print(len(val_subs))\n",
    "print(len(train_subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# verify that we can pass to /from json\n",
    "v_subs_json = [v.to_dict() for v in val_subs]\n",
    "v_subs_orig = [ClueWithSubstitutions.from_dict(v) for v in v_subs_json]\n",
    "assert v_subs_orig == val_subs\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "write_json(train_subs, 'train')\n",
    "write_json(val_subs, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we should have the json on which we will run the experiment.\n",
    "Now we load and evaluate on these cluesets. For the paper we used the best model for T5 (lengths),\n",
    "i.e., second to last row in Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from seq2seq.model_runner import ModelRunner\n",
    "\n",
    "k_model_name = 't5-base'\n",
    "k_ckpt_path = ''    # substitute the checkpoint path\n",
    "\n",
    "def run_model(name):\n",
    "    mr = ModelRunner(k_model_name, k_ckpt_path)\n",
    "\n",
    "    fname = config.DataDirs.DataExport.wordplay_dir / f'{name}_subs.json'\n",
    "    with open(fname, 'r') as f:\n",
    "        clue_sub_list: List[ClueWithSubstitutions] = [ClueWithSubstitutions.from_dict(v) for v in json.load(f)]\n",
    "    all_outputs: List[List[str]] = []\n",
    "    for cws in clue_sub_list:\n",
    "        input_list = [cws.orig_input]\n",
    "        input_list.extend([x.new_clue_str for x in cws.substitutions])\n",
    "        outs = mr.generate(input_list)\n",
    "        outs = [x.tolist() for x in outs]\n",
    "        all_outputs.append(outs)\n",
    "    # to get off a cluster, e.g.\n",
    "    # with open(f'./data_util/{name}_results.json', 'w') as f:\n",
    "    #     json.dump(all_outputs, f)\n",
    "    return all_outputs\n",
    "\n",
    "# alternatively, could write to json and then read back in, e.g. if on cluster\n",
    "train_results = run_model('train')\n",
    "val_results = run_model('val')\n",
    "assert len(train_results) == len(train_subs)\n",
    "assert len(val_results) == len(val_subs)\n",
    "\n",
    "\n",
    "# each output grouping should have 21 entries (1 unchanged, 10 scramble, 10 sub)\n",
    "for i in train_results:\n",
    "    assert len(i) == 21\n",
    "for i in val_results:\n",
    "    assert len(i) == 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import multiset\n",
    "from collections import Counter\n",
    "\n",
    "# adapted from decrypt.common.validation_tools\n",
    "def calc_metrics(substrate_word: str,\n",
    "                 sampled: List[str],\n",
    "                 tgt: str,\n",
    "                 ctr: Counter,\n",
    "                 truncate=None):\n",
    "    \"\"\"Accumulate results in the counter\"\"\"\n",
    "    top_res = 0\n",
    "    in_res = 0\n",
    "    ct_match_first_letter = 0\n",
    "    avg_char_overlap_with_substrate = 0.0\n",
    "    avg_char_overlap_with_target = 0.0\n",
    "\n",
    "    if truncate is not None:\n",
    "        sampled = sampled[:truncate]\n",
    "\n",
    "    substrate_word = substrate_word.lower()\n",
    "    samples_no_spaces = list(map(lambda x: x.lower().replace(' ','').strip(), sampled))\n",
    "    if samples_no_spaces[0] == tgt:\n",
    "        top_res = 1\n",
    "    if tgt in samples_no_spaces:\n",
    "        in_res = 1\n",
    "\n",
    "    substrate_multiset = multiset.Multiset(substrate_word)\n",
    "    target_multiset = multiset.Multiset(tgt)\n",
    "    for s in samples_no_spaces:\n",
    "        if s[0] == substrate_word[0]:\n",
    "            ct_match_first_letter += 1\n",
    "        avg_char_overlap_with_substrate += len(substrate_multiset.intersection(multiset.Multiset(s)))/ len(s)\n",
    "        avg_char_overlap_with_target += len(target_multiset.intersection(multiset.Multiset(s))) / len(s)\n",
    "\n",
    "    ctr['total'] += 1\n",
    "    ctr['top'] += top_res\n",
    "    ctr['in_res'] += in_res\n",
    "    ctr['first_letter'] += ct_match_first_letter / len(sampled)\n",
    "    ctr['char_overlap_sub'] += avg_char_overlap_with_substrate / len(sampled)\n",
    "    ctr['char_overlap_tgt'] += avg_char_overlap_with_target / len(sampled)\n",
    "\n",
    "\n",
    "def eval_(pairs, sample_truncate=3):\n",
    "    ctr_orig = Counter()\n",
    "    ctr_scramble = Counter()\n",
    "    ctr_new = Counter()\n",
    "    for sub_group, result_list in pairs:\n",
    "        orig_substrate = sub_group.word_to_be_swapped\n",
    "        tgt = sub_group.target\n",
    "\n",
    "        # unpack the base result (unmodified), scramble results, and substitution results\n",
    "        # 0, 1-10, 11-20\n",
    "        result_base, result_scramble, result_sub = result_list[0], result_list[1:11], result_list[11:]\n",
    "\n",
    "        # base\n",
    "        calc_metrics(orig_substrate, result_base, tgt, ctr_orig, truncate=sample_truncate)\n",
    "        # scramble\n",
    "        for i in range(10):\n",
    "            calc_metrics(substrate_word=sub_group.substitutions[i].substituted_word,\n",
    "                         sampled=result_scramble[i],\n",
    "                         tgt=tgt,\n",
    "                         ctr=ctr_scramble,\n",
    "                         truncate=sample_truncate)\n",
    "        # substitution\n",
    "        for i in range(10):\n",
    "            calc_metrics(substrate_word=sub_group.substitutions[i+10].substituted_word,\n",
    "                         sampled=result_sub[i],\n",
    "                         tgt=tgt,\n",
    "                         ctr=ctr_new,\n",
    "                         truncate=sample_truncate)\n",
    "    # print the counter results\n",
    "    for c in [ctr_orig, ctr_scramble, ctr_new]:\n",
    "        print()\n",
    "        for k,v in c.items():\n",
    "            print(f'{k}: {v/c[\"total\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_pairs = list(zip(val_subs, val_results))\n",
    "train_pairs = list(zip(train_subs, train_results))\n",
    "\n",
    "truncate=10     # i.e. keep all 10; equivalent to not truncating\n",
    "eval_(val_pairs, sample_truncate=truncate)\n",
    "eval_(train_pairs, sample_truncate=truncate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5  Efrat comparison\n",
    "The Efrat comparison has 3 parts:\n",
    "1. Replication of their results\n",
    "1. Creation and analysis on a word-initial disjoint version of their dataset\n",
    "1. Training and eval of a curricular model with t5-large\n",
    "\n",
    "### Replication\n",
    "1. Download and unzip the cryptonite dataset from https://github.com/aviaefrat/cryptonite/tree/main/data.\n",
    "    - We will use only the naive and official-split\n",
    "    - Place in data/original/cryptonite\n",
    "1. Convert to format for our model\n",
    "1. Create the word initial disjoint split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json_lines\n",
    "from typing import *\n",
    "from decrypt.common.puzzle_clue import BaseClue\n",
    "from decrypt.common.util_data import clue_list_tuple_to_train_split_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load in all cryptonite split\n",
    "def load_split(split_type: str, loc):\n",
    "    output_list = []\n",
    "    file_loc = loc / \"cryptonite-\" + split_type + \".jsonl\"\n",
    "    with open(file_loc, \"rb\") as f:\n",
    "        for line in json_lines.reader(f):\n",
    "            output_list.append(line)\n",
    "    return output_list\n",
    "\n",
    "def baseclue_from_cryptonite_clue(cryptonite_clue: Dict) -> BaseClue:\n",
    "    clue = cryptonite_clue['clue']\n",
    "    soln = cryptonite_clue['answer']\n",
    "    soln = \"\".join(soln.split(\" \"))\n",
    "    enumeration = cryptonite_clue['enumeration']\n",
    "\n",
    "    # strip endings\n",
    "    end = clue.rfind(\"(\")\n",
    "    assert clue[end-1] == \" \"\n",
    "    clue = clue[:end-1]\n",
    "\n",
    "    lens = list(map(int, enumeration.strip(\"()\").split(\",\")))\n",
    "    return BaseClue(clue, lens, soln)\n",
    "\n",
    "# # some tests of above method\n",
    "# def test_baseclue_from_cryptonite():\n",
    "#     pp(list(map(baseclue_from_cryptonite_clue, cryptonite_data_all[:5])))\n",
    "#     # a multiword clue\n",
    "#     for c in cryptonite_data_all:\n",
    "#         if ',' in c['enumeration']:\n",
    "#             pp(baseclue_from_cryptonite_clue(c))\n",
    "#             break\n",
    "# # test_baseclue_from_cryptonite()\n",
    "\n",
    "\n",
    "def crypto_to_our_json_format(crypto_tuple, label: str,\n",
    "                              export_dir,\n",
    "                              verify=False):\n",
    "    def crypto_clues_to_base_clues(input_list):\n",
    "        return list(map(baseclue_from_cryptonite_clue, input_list))\n",
    "\n",
    "    tuple_base_clue_list = tuple(map(crypto_clues_to_base_clues, crypto_tuple))\n",
    "\n",
    "    # make sure our changes make sense\n",
    "    if verify:\n",
    "        for idx in range(3):\n",
    "            for orig, new in zip(crypto_tuple[idx], tuple_base_clue_list[idx]):\n",
    "                assert orig['clue'] == new.clue_with_lengths(), f'{orig}, {new}'\n",
    "                assert orig['answer'].strip() == new.soln_with_spaces, f'{orig}, {new}'\n",
    "\n",
    "    clue_list_tuple_to_train_split_json(tuple_base_clue_list,\n",
    "                                        comment='Cryptonite ' + label,\n",
    "                                        export_dir=export_dir,\n",
    "                                        overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_val_test_official = list(map(lambda x:\n",
    "                                   load_split(x,\n",
    "                                              loc=config.DataDirs.OriginalData.k_cryptonite_offical),\n",
    "                                   ['train', 'val', 'test']))\n",
    "train_val_test_naive = list(map(lambda x:\n",
    "                                load_split(x,\n",
    "                                           loc=config.DataDirs.OriginalData.k_cryptonite_naive),\n",
    "                                ['train', 'val', 'test']))\n",
    "\n",
    "# quick sanity check - should be the same length\n",
    "all_official = [clue for clue_list in train_val_test_official\n",
    "                for clue in clue_list]\n",
    "all_naive = [x for l in train_val_test_naive\n",
    "             for x in l]\n",
    "assert len(all_official) == len(all_naive)\n",
    "print(len(all_official))\n",
    "\n",
    "# produce our json format for their splits\n",
    "crypto_to_our_json_format(train_val_test_official, label='official, theirs', verify=True,\n",
    "                          export_dir=config.DataDirs.DataExport.crypto_naive_disjoint)\n",
    "crypto_to_our_json_format(train_val_test_naive, label='naive', verify=True,\n",
    "                          export_dir=config.DataDirs.DataExport.crypto_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make our disjoint hash split\n",
    "# disjoint set\n",
    "def make_disjoint_json(all_clue_list: List[BaseClue]):\n",
    "    soln_to_clue_map: defaultdict[str, List[BaseClue]] = defaultdict(list)\n",
    "    for bc in tqdm(all_clue_list):\n",
    "        soln_to_clue_map[bc.soln].append(bc)\n",
    "    train_val_test = [[], [], []]\n",
    "    for k, v in soln_to_clue_map.items():\n",
    "        h = safe_hash(k[:2]) % 1000        # tried to make larger to get better split numbers\n",
    "        if h < 899 :\n",
    "            train_val_test[0].extend(v)\n",
    "        elif h < 949:        # h==18\n",
    "            train_val_test[1].extend(v)\n",
    "        else:               # h==19\n",
    "            train_val_test[2].extend(v)\n",
    "    print(list(map(len, train_val_test)))\n",
    "\n",
    "    # now shuffle the lists\n",
    "    rng = random.Random(42)\n",
    "    print(train_val_test[0][:3])\n",
    "    for l in train_val_test:\n",
    "        rng.shuffle(l)\n",
    "    print(train_val_test[0][:3])\n",
    "\n",
    "    assert sum(map(len, train_val_test)) == len(all_clue_list)\n",
    "    return train_val_test\n",
    "\n",
    "clue_list_tuple_to_train_split_json(make_disjoint_json(all_official),\n",
    "                                    comment='Cryptonite disjoint hash, ours',\n",
    "                                    export_dir=config.DataDirs.DataExport.crypto_word_init_disjoint,\n",
    "                                    overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Running their model\n",
    "For the naive split training can go to 20 epochs\n",
    "This will use t5-large\n",
    "\n",
    "1. for naive\n",
    "```python\n",
    "python train_clues.py --default_train=cryptonite --name=cryptonite_naive --project=cryptonite --wandb_dir='./wandb' --data_dir='../data/clue_json/cryptonite/naive'\n",
    "```\n",
    "1. also run the official split by modifying the data_dir\n",
    "\n",
    "1. for word initial disjoint split, best performing model is around step 100k, so we need intraepoch eval\n",
    "```python\n",
    "python train_clues.py --default_train=cryptonite --name=cryptonite_word_init_disjoint --project=cryptonite --wandb_dir='./wandb' --data_dir='../data/clue_json/cryptonite/word_init_disjoint' --val_freq=100\n",
    "```\n",
    "\n",
    "Then we run evaluation on the test set\n",
    "1.  for example,\n",
    "```python\n",
    "python train_clues.py --default_val=cryptonite --name=cryptonite_word_init_disjoint _val --project=cryptonite --wandb_dir='./wandb' --data_dir='../data/clue_json/cryptonite/word_init_disjoint' --test --ckpt_path='./path_to_model_ckpt'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Curricular\n",
    "Finally, we train their model using our curricular approach\n",
    "\n",
    "For example, on word initial disjoint\n",
    "```python\n",
    "python train_clues.py --default_train=cryptonite --name=cryptonite_curr_word_init_disj --project=cryptonite --wandb_dir='./wandb' --data_dir='../data/clue_json/cryptonite/word_init_disjoint' --multitask=cfg_crypto_acw_acwdesc\n",
    "```\n",
    "This curricular approach has one fewer epoch of curricular pretraining. It takes\n",
    "a long time (24 hours) to train since the crossword dataset (ACW) is so large.\n",
    "For this reason, it is better to do curricular training only once (i.e. three epochs), and then\n",
    "for each of the three datasplits, train from the pretrained checkpoint.\n",
    "Pretraining takes roughly 6 hours per epoch.\n",
    "\n",
    "And evaluation is unchanged from above (just adding --test and a checkpoint path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
