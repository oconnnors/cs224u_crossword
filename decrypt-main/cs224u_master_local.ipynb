{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l9kBXR1nt5Sj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT6udpGVoME3",
        "outputId": "33a23e3a-7301-4dbb-c7ff-34b81c71abb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/dom/Desktop/CS224u/cs224u_crossword\n"
          ]
        }
      ],
      "source": [
        "%cd /Users/dom/Desktop/CS224u/cs224u_crossword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMg2suY1sWTd",
        "outputId": "e56bcda5-bd68-4d84-9dd7-b9fd8bd465b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'decrypt-main/'\n",
            "/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq\n"
          ]
        }
      ],
      "source": [
        "%cd decrypt-main/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzBZ9KI_rlax",
        "outputId": "4757119a-c137-43b5-c378-cbf73dbdb165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.1.1-cp38-cp38-macosx_10_13_x86_64.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 2.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from bs4->-r requirements.txt (line 1)) (4.9.3)\n",
            "Collecting joblib>=1.0.0\n",
            "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from beautifulsoup4->bs4->-r requirements.txt (line 1)) (2.0.1)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=b4db1542c09d31208e2dbef7adc8375de256320c3f5beb0285b649b07cd02f7f\n",
            "  Stored in directory: /Users/dom/Library/Caches/pip/wheels/75/78/21/68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4, joblib, threadpoolctl, scikit-learn, tqdm\n",
            "Successfully installed bs4-0.0.1 joblib-1.1.0 scikit-learn-1.1.1 threadpoolctl-3.1.0 tqdm-4.64.0\n",
            "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.1 is available.\n",
            "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VY1hB_6tNot",
        "outputId": "2e3c58fe-92de-4cf1-e5c1-3da6b14c2532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  disjoint.json.zip\n",
            "  inflating: disjoint.json           \n",
            "\n",
            "Archive:  naive_random.json.zip\n",
            "  inflating: naive_random.json       \n",
            "\n",
            "Archive:  disjoint_word_init.json.zip\n",
            "  inflating: disjoint_word_init.json  \n",
            "\n",
            "Archive:  guardian_2020_10_08.json.zip\n",
            "  inflating: guardian_2020_10_08.json  \n",
            "\n",
            "4 archives were successfully processed.\n"
          ]
        }
      ],
      "source": [
        "!pushd ./data && unzip \"*.json.zip\" && popd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X1cxG4JjtqzD"
      },
      "outputs": [],
      "source": [
        "sys.path.append('/content/drive/MyDrive/github/cs224u_crossword/decrypt-main/decrypt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10Dl0Xhougrl",
        "outputId": "119afaf0-1748-4c08-be23-3d950c3497e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/github/cs224u_crossword/decrypt-main\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/github/cs224u_crossword/decrypt-main/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__swuCCatV38",
        "outputId": "480d784c-fee3-4961-89ba-00dd292a0162"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:decrypt.scrape_parse.guardian_load:Loading splits directly from given json files. Using /Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/data/naive_random.json\n",
            "100%|██████████| 142380/142380 [00:00<00:00, 166161.10it/s]\n",
            "INFO:decrypt.scrape_parse.guardian_load:Counter({1: 118540, 2: 20105, 3: 2929, 4: 686, 5: 112, 6: 8})\n",
            "INFO:decrypt.scrape_parse.guardian_load:Clue list length matches Decrypting paper expected length\n",
            "INFO:decrypt.scrape_parse.guardian_load:Got splits of lenghts [85428, 28476, 28476]\n",
            "INFO:decrypt.scrape_parse.guardian_load:First three clues of train set:\n",
            "\t[CleanGuardianClue(clue='Suffering to grasp edge of plant', lengths=[8], soln='agrimony', soln_with_spaces='agrimony', idx=-1, dataset='', across_or_down='', pos=(0, 0), unique_clue_id='', type='cryptic', number=0, id='', creator='Chifonie', orig_lengths='8', lengths_punctuation=set()), CleanGuardianClue(clue='Honour Ben and Noel with new order', lengths=[7], soln='ennoble', soln_with_spaces='ennoble', idx=-1, dataset='', across_or_down='', pos=(0, 0), unique_clue_id='', type='cryptic', number=0, id='', creator='Rufus', orig_lengths='7', lengths_punctuation=set()), CleanGuardianClue(clue='Bit the royal we love? Cheers!', lengths=[4], soln='iota', soln_with_spaces='iota', idx=-1, dataset='', across_or_down='', pos=(0, 0), unique_clue_id='', type='cryptic', number=0, id='', creator='Screw', orig_lengths='4', lengths_punctuation=set())]\n"
          ]
        }
      ],
      "source": [
        "from decrypt.scrape_parse import (\n",
        "  load_guardian_splits,               # naive random split\n",
        "  load_guardian_splits_disjoint,      # answer-disjoint split\n",
        "  load_guardian_splits_disjoint_hash  # word-initial disjoint split\n",
        ")\n",
        "from decrypt.scrape_parse.guardian_load import SplitReturn\n",
        "\"\"\"\n",
        "each of these methods returns a tuple of `SplitReturn`\n",
        "- soln to clue map (string to List of clues mapping to that soln): Dict[str, List[BaseClue]\n",
        "this enables seeing all clues associated with a given answer word\n",
        "- list of all clues (List[BaseClue])\n",
        "- Tuple of three lists (the train, val, test splits), each is List[BaseClue]\n",
        "\n",
        "Note that\n",
        "load_guardian_splits() will verify that\n",
        "- total glob length matches the one in paper (ie. number of puzzles downloaded matches)\n",
        "- total clue set length matches the one in paper (i.e. filtering is the same)\n",
        "- one of the clues in our train set matches our train set (i.e. a single clue\n",
        "spot check for randomness)\n",
        "If you get an assertion error or an exception during load, please file an\n",
        "issue, since the splits should be identical\n",
        "Alternatively, if you don't care, you can pass `verify=False` to\n",
        "`load_guardian_splits`\n",
        "\"\"\"\n",
        "\n",
        "soln_to_clue_map, all_clues_list, (train, val, test) = load_guardian_splits()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5xzCItm77OL"
      },
      "source": [
        "# Baseline t5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT9W0VEe8HGt",
        "outputId": "9efbc55a-b1f2-4350-9155-919343a1f81f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/baselines\n"
          ]
        }
      ],
      "source": [
        "%cd baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDiYWMvJ_F7G",
        "outputId": "83450139-aeee-4276-c234-49656961fa1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%apt` not found.\n"
          ]
        }
      ],
      "source": [
        "%brew install enchant\n",
        "%pip install pyenchant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG1NJGwW8ESm",
        "outputId": "d74c2997-880f-48f0-dcc9-29478ce2143b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from decrypt.scrape_parse import (\n",
        "    load_guardian_splits,\n",
        "    load_guardian_splits_disjoint,\n",
        "    load_guardian_splits_disjoint_hash\n",
        ")\n",
        "\n",
        "import os\n",
        "from decrypt import config\n",
        "from decrypt.common import validation_tools as vt\n",
        "from decrypt.common.util_data import clue_list_tuple_to_train_split_json\n",
        "import logging\n",
        "logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "k_json_folder = config.DataDirs.Guardian.json_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-ev1lRX8M1H",
        "outputId": "551506d0-f01e-4b77-eebd-4664a4d56e6d"
      },
      "outputs": [],
      "source": [
        "def make_dataset(split_type: str, overwrite=False):\n",
        "    assert split_type in ['naive_random', 'naive_disjoint', 'word_init_disjoint']\n",
        "    if split_type == 'naive_random':\n",
        "        load_fn = load_guardian_splits\n",
        "        tgt_dir = config.DataDirs.DataExport.guardian_naive_random_split\n",
        "    elif split_type == 'naive_disjoint':\n",
        "        load_fn = load_guardian_splits_disjoint\n",
        "        tgt_dir = config.DataDirs.DataExport.guardian_naive_disjoint_split\n",
        "    else:\n",
        "        load_fn = load_guardian_splits_disjoint_hash\n",
        "        tgt_dir = config.DataDirs.DataExport.guardian_word_init_disjoint_split\n",
        "\n",
        "    _, _, (train, val, test) = load_fn(k_json_folder)\n",
        "\n",
        "    os.makedirs(tgt_dir, exist_ok=True)\n",
        "    # write the output as json\n",
        "    try:\n",
        "        clue_list_tuple_to_train_split_json((train, val, test),\n",
        "                                            comment=f'Guardian data. Split: {split_type}',\n",
        "                                            export_dir=tgt_dir,\n",
        "                                            overwrite=overwrite)\n",
        "    except FileExistsError:\n",
        "        logging.warning(f'You have already generated the {split_type} dataset.\\n'\n",
        "                        f'It is located at {tgt_dir}\\n'\n",
        "                        f'To regenerate, pass overwrite=True or delete it\\n')\n",
        "\n",
        "\n",
        "make_dataset('naive_random')\n",
        "make_dataset('word_init_disjoint')\n",
        "# you can also make_dataset('naive_disjoint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zGWP4avE1LB",
        "outputId": "7da9f3be-87c0-49b2-c3f7-4f687db98e67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.4.2\n",
            "  Using cached transformers-4.4.2-py3-none-any.whl (2.0 MB)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp39-cp39-macosx_10_11_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Using cached sacremoses-0.0.53.tar.gz (880 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: packaging in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from transformers==4.4.2) (21.3)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2022.4.24-cp39-cp39-macosx_10_9_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from transformers==4.4.2) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from transformers==4.4.2) (4.64.0)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from transformers==4.4.2) (2.27.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from packaging->transformers==4.4.2) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from requests->transformers==4.4.2) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from requests->transformers==4.4.2) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from requests->transformers==4.4.2) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from requests->transformers==4.4.2) (2022.5.18.1)\n",
            "Requirement already satisfied: six in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from sacremoses->transformers==4.4.2) (1.16.0)\n",
            "Requirement already satisfied: click in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from sacremoses->transformers==4.4.2) (8.1.3)\n",
            "Requirement already satisfied: joblib in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from sacremoses->transformers==4.4.2) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=17b50e374ead31b8c10c7222323b277e75508057f460cbf17f1519a23b817632\n",
            "  Stored in directory: /Users/dom/Library/Caches/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, regex, filelock, sacremoses, transformers\n",
            "Successfully installed filelock-3.7.1 regex-2022.4.24 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.4.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: wandb in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (0.12.17)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (1.0.9)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (5.9.1)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (3.20.1)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (62.3.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (1.16.0)\n",
            "Requirement already satisfied: PyYAML in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (1.5.12)\n",
            "Requirement already satisfied: setproctitle in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (1.2.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp39-none-macosx_10_9_x86_64.whl (110.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from torch==1.7.1) (1.22.4)\n",
            "Installing collected packages: typing-extensions, torch\n",
            "Successfully installed torch-1.7.1 typing-extensions-4.2.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp39-cp39-macosx_10_9_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=4.1.1\n",
            "  Downloading Pillow-9.1.1-cp39-cp39-macosx_10_10_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from torchvision==0.8.2) (1.22.4)\n",
            "Requirement already satisfied: torch==1.7.1 in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from torchvision==0.8.2) (1.7.1)\n",
            "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/224ufinal/lib/python3.9/site-packages (from torch==1.7.1->torchvision==0.8.2) (4.2.0)\n",
            "Installing collected packages: pillow, torchvision\n",
            "Successfully installed pillow-9.1.1 torchvision-0.8.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers==4.4.2\n",
        "%pip install wandb\n",
        "%pip install torch==1.7.1\n",
        "%pip install torchvision==0.8.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfY_llgXHfHd",
        "outputId": "d4c415e0-d098-41ac-be1a-f01a18489019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq\n"
          ]
        }
      ],
      "source": [
        "%cd /Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLR5rbehZYeQ",
        "outputId": "07075e34-4ea1-419e-f002-788b788efbb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting overrides\n",
            "  Downloading overrides-6.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting typing-utils>=0.0.3\n",
            "  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: typing-utils, overrides\n",
            "Successfully installed overrides-6.1.0 typing-utils-0.1.0\n",
            "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.1 is available.\n",
            "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install overrides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import typing\n",
        "import abc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:1jv42879) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">base_line_naive</strong>: <a href=\"https://wandb.ai/224u-s22-cryptic-crosswords/baseline/runs/1jv42879\" target=\"_blank\">https://wandb.ai/224u-s22-cryptic-crosswords/baseline/runs/1jv42879</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220602_145912-1jv42879/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:1jv42879). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.17"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/wandb/run-20220602_145929-wgzeixmg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/224u-s22-cryptic-crosswords/baseline/runs/wgzeixmg\" target=\"_blank\">baseline_naive</a></strong> to <a href=\"https://wandb.ai/224u-s22-cryptic-crosswords/baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/224u-s22-cryptic-crosswords/baseline/runs/wgzeixmg?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x122062d60>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"baseline\", entity=\"224u-s22-cryptic-crosswords\",name=\"baseline_naive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5-31-package-list.txt     cs224u_master_local.ipynb requirements.txt\n",
            "LICENSE                   \u001b[34mdata\u001b[m\u001b[m                      \u001b[34mseq2seq\u001b[m\u001b[m\n",
            "README.md                 \u001b[34mdecrypt\u001b[m\u001b[m                   \u001b[34mwandb\u001b[m\u001b[m\n",
            "\u001b[34mbaselines\u001b[m\u001b[m                 \u001b[34mexperiments\u001b[m\u001b[m\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIEbCh9YG_Ba",
        "outputId": "b30dd294-9e0f-4035-c163-71f9c3c98436"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:1wbiihk9) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">baseline_naive</strong>: <a href=\"https://wandb.ai/224u-s22-cryptic-crosswords/baseline/runs/1wbiihk9\" target=\"_blank\">https://wandb.ai/224u-s22-cryptic-crosswords/baseline/runs/1wbiihk9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220602_162536-1wbiihk9/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:1wbiihk9). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.17"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/wandb/run-20220602_162647-3n8z5l3g</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/224u-s22-cryptic-crosswords/baseline/runs/3n8z5l3g\" target=\"_blank\">baseline_naive</a></strong> to <a href=\"https://wandb.ai/224u-s22-cryptic-crosswords/baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "baseline_naive\n"
          ]
        }
      ],
      "source": [
        "#/usr/bin/env python3\n",
        "import wandb\n",
        "\n",
        "run = wandb.init(project=\"baseline\", entity=\"224u-s22-cryptic-crosswords\",name=\"baseline_naive\")\n",
        "print(run.name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdterr\u001b[0m (\u001b[33m224u-s22-cryptic-crosswords\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/wandb/run-20220602_163126-3434cqhw\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline_naive\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/224u-s22-cryptic-crosswords/baseline\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/224u-s22-cryptic-crosswords/baseline/runs/3434cqhw\u001b[0m\n",
            "WARNING:common_seq.util:Logger had handlers already set WTF\n",
            "..... CLEARING\n",
            "[06.02 16:31:31] [train_clues.py:132 - <module>()]\t train_clues.py --default_train=base --name=baseline_naive --project=baseline --wandb_dir=./wandb --data_dir=../data/clue_json/guardian/naive_random\n",
            "[06.02 16:31:31] [util.py:160 - set_seed()]\t Setting seed\n",
            "[06.02 16:31:31] [util_checkpoint.py:65 - __init__()]\t Saver will track (metric, maximize?)\n",
            " [('dev/num_match_top_sampled', True), ('epoch', True)]\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/train_clues.py\", line 158, in <module>\n",
            "    local_trainer = ClueTrainer(wandb.config, local_rh, aux_config=aux_config)\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/train_clues.py\", line 26, in __init__\n",
            "    super().__init__(config, rh, **kwargs)\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/train_abc.py\", line 751, in __init__\n",
            "    super().__init__(config, rh, **kwargs)\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/train_abc.py\", line 255, in __init__\n",
            "    self.setup_model_and_device()       # populate 3 above; potentially add special tokens\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/train_abc.py\", line 377, in setup_model_and_device\n",
            "    self.device, self.gpu_ids = util.get_available_devices(assert_cuda=True)\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/common_seq/util.py\", line 75, in get_available_devices\n",
            "    raise ValueError('no cuda found')\n",
            "ValueError: no cuda found\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   dev/num_match_in_sample best_in_sample\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: dev/num_match_top_sampled best_top_sampled\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mbaseline_naive\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/224u-s22-cryptic-crosswords/baseline/runs/3434cqhw\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/wandb/run-20220602_163126-3434cqhw/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python train_clues.py --default_train=base --name=baseline_naive --project=baseline --wandb_dir='./wandb' --data_dir='../data/clue_json/guardian/naive_random'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Curricular training\n",
        "At this point you should have a files at\n",
        "\n",
        "./data/clue_json/curricular/ACW/train.json\n",
        "./data/clue_json/curricular/anagram/[train.json, anag_indics.json]\n",
        "Running curricular training is the same as running main t5 vanilla train, except that we pass an extra multitask flag, which specifies the curriculum to use. See seq2seq/multitask_config. You should pass one of the names from multi_config dict in that file\n",
        "\n",
        "For example, to train the naive split with the top performing curricular approach (i.e. the result in table 3 that is ACW + ACW-descramble)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdterr\u001b[0m (\u001b[33m224u-s22-cryptic-crosswords\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/wandb/run-20220602_163312-1iy68p1t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mnaive_top_curricular\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/224u-s22-cryptic-crosswords/curricular\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/224u-s22-cryptic-crosswords/curricular/runs/1iy68p1t\u001b[0m\n",
            "WARNING:common_seq.util:Logger had handlers already set WTF\n",
            "..... CLEARING\n",
            "[06.02 16:33:17] [train_clues.py:132 - <module>()]\t train_clues.py --default_train=base --name=naive_top_curricular --project=curricular --wandb_dir=./wandb --data_dir=../data/clue_json/guardian/naive_random --multitask=ACW__ACW_descramble\n",
            "[06.02 16:33:17] [util.py:160 - set_seed()]\t Setting seed\n",
            "[06.02 16:33:17] [util_checkpoint.py:65 - __init__()]\t Saver will track (metric, maximize?)\n",
            " [('dev/num_match_top_sampled', True), ('multisave', True), ('multi/acw/num_match_in_sample', True), ('epoch', True)]\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/train_clues.py\", line 158, in <module>\n",
            "    local_trainer = ClueTrainer(wandb.config, local_rh, aux_config=aux_config)\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/train_clues.py\", line 26, in __init__\n",
            "    super().__init__(config, rh, **kwargs)\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/train_abc.py\", line 751, in __init__\n",
            "    super().__init__(config, rh, **kwargs)\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/train_abc.py\", line 255, in __init__\n",
            "    self.setup_model_and_device()       # populate 3 above; potentially add special tokens\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/train_abc.py\", line 377, in setup_model_and_device\n",
            "    self.device, self.gpu_ids = util.get_available_devices(assert_cuda=True)\n",
            "  File \"/Users/dom/Desktop/CS224u/cs224u_crossword/decrypt-main/seq2seq/common_seq/util.py\", line 75, in get_available_devices\n",
            "    raise ValueError('no cuda found')\n",
            "ValueError: no cuda found\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   dev/num_match_in_sample best_in_sample\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: dev/num_match_top_sampled best_top_sampled\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mnaive_top_curricular\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/224u-s22-cryptic-crosswords/curricular/runs/1iy68p1t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/wandb/run-20220602_163312-1iy68p1t/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python train_clues.py --default_train=base --name=naive_top_curricular --project=curricular --wandb_dir='./wandb' --data_dir='../data/clue_json/guardian/naive_random' --multitask=ACW__ACW_descramble"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "cs224u_master.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "801dc401bfe477544045a8dc83d63efd6a32868ac2a652a4fbe6d30f82d2d95a"
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('224ufinal')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
